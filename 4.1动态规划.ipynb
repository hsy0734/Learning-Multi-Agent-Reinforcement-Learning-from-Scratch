{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f6f334",
   "metadata": {},
   "source": [
    "强化学习包括策略评估和策略控制\n",
    "策略评估就是求价值函数和Q函数\n",
    "自举法：用估计值来改进估计值的方法\n",
    "迭代策略评估：用V0更新V1，用V1更新V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        self.action_space=[0,1,2,3]\n",
    "        self.action_meaning={\n",
    "            0:\"UP\",\n",
    "            1:\"DOWN\",\n",
    "            2:\"LEFT\",\n",
    "            3:\"RIGHT\",\n",
    "        }\n",
    "        self.reward_map=np.array(\n",
    "            [[0,0,0,1.0],\n",
    "            [0,None,0,-1.0],\n",
    "            [0,0,0,0]]\n",
    "        )\n",
    "        self.goal_state=(0,3)\n",
    "        self.wall_state=(1,1)\n",
    "        self.start_state=(2,0)\n",
    "        self.agent_state=self.start_state\n",
    "    \n",
    "    @property\n",
    "    def height(self):\n",
    "        return len(self.reward_map)\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        return len(self.reward_map[0])\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.reward_map.shape\n",
    "\n",
    "    def actions(self):\n",
    "        return self.action_space \n",
    "    \n",
    "    def states(self):\n",
    "        for h in range(self.height):\n",
    "            for w in range(self.width):\n",
    "                yield(h,w)\n",
    "\n",
    "    def next_state(self,state,action):\n",
    "        #计算移动的目的地\n",
    "        action_move_map=[(-1,0),(1,0),(0,-1),(0,1)]\n",
    "        move=action_move_map[action]\n",
    "        next_state=(state[0]+move[0],state[1]+move[1])\n",
    "        ny,nx=next_state\n",
    "        \n",
    "        #判断目的地是世界边缘之外还是在墙外\n",
    "        if nx<0 or nx>=self.width or ny<0 or ny >=self.height:\n",
    "            next_state=state\n",
    "        elif next_state==self.wall_state:\n",
    "            next_state=state\n",
    "        return next_state\n",
    "    def reward(self,state,action,next_state):\n",
    "        return self.reward_map[next_state]\n",
    "\n",
    "    def render_v(self, v=None):\n",
    "        # 简单的控制台渲染方法，显示状态价值或奖励\n",
    "        for h in range(self.height):\n",
    "            row = []\n",
    "            for w in range(self.width):\n",
    "                state = (h, w)\n",
    "                if state == self.wall_state:\n",
    "                    row.append(\"  WALL  \")\n",
    "                elif v is not None and state in v:\n",
    "                    row.append(f\" {v[state]:7.2f} \")\n",
    "                else:\n",
    "                    r = self.reward_map[h, w]\n",
    "                    if r is None:\n",
    "                        row.append(\"  None  \")\n",
    "                    else:\n",
    "                        row.append(f\" {float(r):7.2f} \")\n",
    "            print(\"|\".join(row))\n",
    "\n",
    "env = GridWorld()\n",
    "env.render_v()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
